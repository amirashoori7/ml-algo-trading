{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42803c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        low       high       open      close      volume\n",
      "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
      "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
      "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
      "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n",
      "4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv('./data-source/crypto_data/LTC-USD.csv', \n",
    "                  names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7474ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD\n",
      "LTC-USD\n",
      "BCH-USD\n",
      "ETH-USD\n",
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \n",
      "time                                                                      \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083  \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400  \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646  \n",
      "1528968900     870.000000        1.680500      486.00000       77.355759  \n",
      "1528968960     869.989990        1.669014      486.00000        7.503300  \n"
     ]
    }
   ],
   "source": [
    "# create a dataframe with close and volume data of 4 cryptos combined from 4 different csv files\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "cryptos = ['BTC-USD', 'LTC-USD', 'BCH-USD', 'ETH-USD']\n",
    "for crypto in cryptos:\n",
    "    print(crypto)\n",
    "    dataset = f'./data-source/crypto_data/{crypto}.csv'\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "    df.rename(columns={'close': f'{crypto}_close', 'volume': f'{crypto}_volume'}, inplace=True)\n",
    "    df.set_index('time', inplace=True)\n",
    "    df = df[[f'{crypto}_close', f'{crypto}_volume']]\n",
    "    \n",
    "    if len(main_df) == 0:\n",
    "        main_df = df \n",
    "    else:\n",
    "        main_df = main_df.join(df)\n",
    "        \n",
    "main_df.fillna(method='ffill', inplace=True)\n",
    "main_df.dropna(inplace=True)\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d18575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083   \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400   \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646   \n",
      "1528968900     870.000000        1.680500      486.00000       77.355759   \n",
      "1528968960     869.989990        1.669014      486.00000        7.503300   \n",
      "\n",
      "               future  target  \n",
      "time                           \n",
      "1528968720  96.389999       0  \n",
      "1528968780  96.519997       0  \n",
      "1528968840  96.440002       0  \n",
      "1528968900  96.470001       1  \n",
      "1528968960  96.400002       0  \n"
     ]
    }
   ],
   "source": [
    "# Create a Target, choose how Far Out to Predict\n",
    "# We can make prediction A Regression Question using a Linear Activation with the output layer\n",
    "# Instead we go with Binary Classification Here:\n",
    "\n",
    "SEQ_LEN = 60 # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3 # how far into future to predict\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "\n",
    "# Simple Classification Function\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# To do this we need a future column\n",
    "# shift will just shift the columns for us\n",
    "# A Negative \n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "# Now we use the future values to make a target\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef4a89",
   "metadata": {},
   "source": [
    "Since our sample data here is 1min sequential, we have to separate out the validation data.\n",
    "what we did above was shuffle data then slice it which results in overfitting pour over into the validation set.\n",
    "So we'll take the last 5% of the data, then balance and normalize it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c934e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(main_df.index.values) #get the times\n",
    "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))] #get the last 5% of the times\n",
    "\n",
    "#make validation data where the index is in the last 5%\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "\n",
    "#now the main_df contains all the data up to the last 5%\n",
    "main_df = main_df[(main_df.index < last_5pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df391df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance and normalize data\n",
    "\n",
    "#train_x, train_y = preprocess_df(main_df) validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1) #don't need the fututre anymore\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True) #remove nas created bt percentage change\n",
    "            df[col] = preprocessing.scale(df[col].values) #scale between 0 and 1\n",
    "            \n",
    "    df.dropna(inplace=True) #cleanup NaNs again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960f42b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ac121e6beee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprev_days\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#store all but the target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_days\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msequential_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shuffle for good measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#next we create our actual sequences\n",
    "\n",
    "sequential_data = []\n",
    "prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "for i in df.values:\n",
    "    prev_days.append([n for n in i[:-1]]) #store all but the target\n",
    "    if len(prev_days) == SEQ_LEN:\n",
    "        sequential_data.append([np.array(prev_days), i[-1]])\n",
    "        \n",
    "random.shuffle(sequential_data) #shuffle for good measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47673a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
